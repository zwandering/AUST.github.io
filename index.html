<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="AesStyler: Aesthetic Guided Universal Style Transfer.">
  <meta name="keywords" content="Aesthetic, style transfer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AesStyler: Aesthetic Guided Universal Style Transfer</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--  <link rel="icon" href="./static/images/favicon.svg">-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AesStyler: Aesthetic Guided Universal Style Transfer</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zwandering.github.io">Haokun Zhu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yiranran.github.io">Ran Yi</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=Jm5qsAYAAAAJ/">Teng Hu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=0i-Nzv0AAAAJ&hl=en">Yu-Kun Lai</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=V5E7JXsAAAAJ&hl=en">Paul L. Rosin</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University,</span>
            <span class="author-block"><sup>2</sup>Cardiff University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
<!--               PDF Link.-->
<span class="link-block">
  <a href="message.html" target="_blank"
     class="external-link button is-normal is-rounded is-dark">
    <span class="icon">
        <i class="fas fa-file-pdf"></i>
    </span>
    <span>Paper</span>
  </a>
</span>

<!--              <span class="link-block">-->
<!--                <a href="https://arxiv.org/abs/2011.12948"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="ai ai-arxiv"></i>-->
<!--                  </span>-->
<!--                  <span>arXiv</span>-->
<!--                </a>-->
<!--              </span>-->
<!--              &lt;!&ndash; Video Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
<!--              &lt;!&ndash; Code Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-github"></i>-->
<!--                  </span>-->
<!--                  <span>Code</span>-->
<!--                  </a>-->
<!--              </span>-->
<!--              &lt;!&ndash; Dataset Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--<section class="hero teaser">-->
<!--  <div class="container is-max-desktop">-->
<!--    <div class="hero-body">-->
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="./static/videos/teaser.mp4"-->
<!--                type="video/mp4">-->
<!--      </video>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into-->
<!--        free-viewpoint-->
<!--        portraits.-->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Recent studies have shown impressive progress in universal style transfer which can integrate
            arbitrary styles into content images. However, existing approaches struggle with low aesthetics
            and disharmonious patterns in the final results due to the following problems:
            <strong>(1) Aesthetic Assumption Bias</strong>: In the training stage, the aesthetic discriminator of AesUST lacks explicit supervisory signals to define aesthetics,
instead it presumes that images from the style training dataset inherently possess aestheticsâ€”a presumption that is not guaranteed to be accurate.
This can lead to it acting more as a style feature extractor, potentially overlooking true aesthetic elements.

            <strong>(2) Style-Constrained Aesthetic Extraction</strong>>: AesUST restricts aesthetic feature extraction to style images, leading to a narrow, style-specific aesthetic perspective. However, aesthetics generally have universal qualities and shouldn't be confined as style-specific.
<strong>(3) Indiscriminate Feature Fusion</strong>:
attention scores recalibrate high layer feature maps of aesthetic and style features. However, these modified features are then merged with content features without adequately considering the differences in feature distributions and information from lower layers.
          </p>
          <p>
            To this end, we propose <strong>AesStyler, a novel Aesthetic Guided Universal Style Transfer method</strong>.
Firstly, we propose to utilize TANet as the aesthetic feature extractor in AesStyler.
Secondly, we propose to build a <strong>Universal Aesthetic Codebook (UAC)</strong>, to harness and utilize universal aesthetic features which encapsulate the global aspects of aesthetics.
Thirdly, we propose the <strong>Universal and Style-specific Aesthetic-Guided Attention (USAesA)</strong> module.
USAesA empowers our model to adaptively and progressively integrate both universal and style-specific aesthetic features with the style feature and incorporate the aes-enhanced style feature into the content feature.
Extensive experiments and \yl{user studies} have demonstrated the superiority of our approach. Compared to previous methods, our AesStyler not only yields results of superior aesthetics but also with better style transfer quality.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Methods</h2>
        <div class="content has-text-justified">
          <p>
            We will release the details of the method after the review of CVPR2024.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Experiment Results</h2>
        <div class="content has-text-justified">
          <p>
            We compare our proposed AesSTyler against 10 state-of-the-art arbitrary style transfer methods: aesthetic-aware UST methods (AesUST and AAST), aesthetic-free UST methods (AdaAttN, Avatar, ArtFlow, IECAST, MAST, AdaIN, SANet and StyleFormer.
          </p>
        </div>
        <!-- Re-rendering. -->
        <h3 class="title is-4">Qualitative Experiment Results</h3>

        <div class="content has-text-centered">
<img src="static/images/main_comparison_1_00.png" alt="PontTuset" width="1600" style="border-style: none">
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
        <div class="columns is-centered">
      <div class="column is-full-width">

        <!-- Re-rendering. -->
        <h3 class="title is-4">Quantitative Experiment Results</h3>
        <div class="content has-text-centered">
        <table border="1">
           <caption>Quantitative comparisons with state-of-the-art UST methods. <strong>Bold</strong> and <u>Underline</u> indicate best and second-best results.</caption>
  <tr>
    <th></th>
    <th>Ours</th>
    <th>AesUST</th>
    <th>AAST</th>
    <th>AdaAttN</th>
    <th>Avatar</th>
    <th>ArtFlow</th>
    <th>IECAST</th>
    <th>MAST</th>
    <th>AdaIN</th>
    <th>StyleFormer</th>
  </tr>
  <tr>
    <td>Gram Loss â†“</td>
    <td><strong>0.1710</strong></td>
    <td>0.2192</td>
    <td>0.1756</td>
    <td>0.2088</td>
    <td>0.2614</td>
    <td>0.2046</td>
    <td>0.2641</td>
    <td>0.1916</td>
    <td>0.1913</td>
    <td><u>0.1713</u></td>
  </tr>
  <tr>
    <td>SSIM â†‘</td>
    <td><u>0.3971</u></td>
    <td>0.3330</td>
    <td>0.2780</td>
    <td><strong>0.4311</strong></td>
    <td>0.2449</td>
    <td>0.3966</td>
    <td>0.3392</td>
    <td>0.2945</td>
    <td>0.2668</td>
    <td>0.3354</td>
  </tr>
  <tr>
    <td>Aes Score â†‘</td>
    <td><strong>0.4597</strong></td>
    <td>0.4102</td>
    <td>0.4020</td>
    <td><u>0.4180</u></td>
    <td>0.4100</td>
    <td>0.4056</td>
    <td>0.4137</td>
    <td>0.4065</td>
    <td>0.4046</td>
    <td>0.4109</td>
  </tr>
  <tr>
    <td>Deception Rateâ†‘</td>
    <td><strong>0.2857</strong></td>
    <td>0.1885</td>
    <td>0.2176</td>
    <td><u>0.2761</u></td>
    <td>0.2620</td>
    <td>0.1846</td>
    <td>0.1811</td>
    <td>0.2730</td>
    <td>0.1363</td>
    <td>0.2330</td>
  </tr>
</table>

        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
      <div class="container is-max-desktop">
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">More Experiment Results</h2>
        <div class="content has-text-justified">
          <p>
            We will showm more experiment results after the review of CVPR2024.
          </p>
        </div>

      </div>
    </div>
  </div>
    <!--/ Animation. -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<!--<section class="section" id="BibTeX">-->
<!--  <div class="container is-max-desktop content">-->
<!--    <h2 class="title">BibTeX</h2>-->
<!--    <pre><code>@article{park2021nerfies,-->
<!--  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},-->
<!--  title     = {Nerfies: Deformable Neural Radiance Fields},-->
<!--  journal   = {ICCV},-->
<!--  year      = {2021},-->
<!--}</code></pre>-->
<!--  </div>-->
<!--</section>-->


<footer class="footer">
  <div class="container">
<!--    <div class="content has-text-centered">-->
<!--      <a class="icon-link"-->
<!--         href="./static/videos/nerfies_paper.pdf">-->
<!--        <i class="fas fa-file-pdf"></i>-->
<!--      </a>-->
<!--      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>-->
<!--        <i class="fab fa-github"></i>-->
<!--      </a>-->
<!--    </div>-->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
